{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "5FSNOfH80lel"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess data\n",
        "data = pd.read_csv('sonar.csv', header=None)\n",
        "X = data.iloc[:, :-1].values\n",
        "y = (data.iloc[:, -1] == 'R').astype(int).values  # Convert R/M to 1/0"
      ],
      "metadata": {
        "id": "3ZgsCxe10qsJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "UffStsWw0x3t"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "Rvzi8RDS00Hf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp45OvU102-i",
        "outputId": "12d4ab31-d811-4d26-9ca7-22a353350b28"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "uM3MmW5g05tz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haEItJae07P8",
        "outputId": "927bc891-1a59-4941-f6b3-9ba053a0dda9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.5093 - loss: 0.7683 - val_accuracy: 0.6471 - val_loss: 0.6762\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5609 - loss: 0.6920 - val_accuracy: 0.6765 - val_loss: 0.6499\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7337 - loss: 0.6138 - val_accuracy: 0.7353 - val_loss: 0.6333\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6813 - loss: 0.6109 - val_accuracy: 0.7353 - val_loss: 0.6118\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8120 - loss: 0.5083 - val_accuracy: 0.7353 - val_loss: 0.5858\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8026 - loss: 0.5166 - val_accuracy: 0.7647 - val_loss: 0.5602\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7528 - loss: 0.4995 - val_accuracy: 0.7941 - val_loss: 0.5338\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8336 - loss: 0.4480 - val_accuracy: 0.7941 - val_loss: 0.5102\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8326 - loss: 0.4102 - val_accuracy: 0.7941 - val_loss: 0.4911\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8244 - loss: 0.3758 - val_accuracy: 0.7941 - val_loss: 0.4682\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8361 - loss: 0.3830 - val_accuracy: 0.7941 - val_loss: 0.4499\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8669 - loss: 0.3408 - val_accuracy: 0.7647 - val_loss: 0.4366\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8909 - loss: 0.3295 - val_accuracy: 0.7647 - val_loss: 0.4230\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8957 - loss: 0.2797 - val_accuracy: 0.7941 - val_loss: 0.4119\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8747 - loss: 0.2942 - val_accuracy: 0.7941 - val_loss: 0.4128\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8697 - loss: 0.2869 - val_accuracy: 0.8235 - val_loss: 0.4129\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8662 - loss: 0.3003 - val_accuracy: 0.8235 - val_loss: 0.4072\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9313 - loss: 0.1948 - val_accuracy: 0.8235 - val_loss: 0.4043\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9152 - loss: 0.2250 - val_accuracy: 0.8235 - val_loss: 0.4042\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8998 - loss: 0.2124 - val_accuracy: 0.8235 - val_loss: 0.4088\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9067 - loss: 0.2101 - val_accuracy: 0.8235 - val_loss: 0.4426\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9268 - loss: 0.2244 - val_accuracy: 0.8235 - val_loss: 0.4486\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9322 - loss: 0.1747 - val_accuracy: 0.8235 - val_loss: 0.4491\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9734 - loss: 0.1427 - val_accuracy: 0.8235 - val_loss: 0.4546\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9519 - loss: 0.1335 - val_accuracy: 0.8824 - val_loss: 0.4453\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9545 - loss: 0.1272 - val_accuracy: 0.8235 - val_loss: 0.4394\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9528 - loss: 0.1246 - val_accuracy: 0.7941 - val_loss: 0.4336\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9273 - loss: 0.1456 - val_accuracy: 0.7941 - val_loss: 0.4107\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9609 - loss: 0.1214 - val_accuracy: 0.7941 - val_loss: 0.3745\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9691 - loss: 0.1259 - val_accuracy: 0.8235 - val_loss: 0.3698\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9673 - loss: 0.1155 - val_accuracy: 0.8235 - val_loss: 0.4002\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9785 - loss: 0.0871 - val_accuracy: 0.8235 - val_loss: 0.4405\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9811 - loss: 0.0678 - val_accuracy: 0.8235 - val_loss: 0.4646\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9513 - loss: 0.1238 - val_accuracy: 0.8235 - val_loss: 0.4622\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9811 - loss: 0.0601 - val_accuracy: 0.8235 - val_loss: 0.4740\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9589 - loss: 0.0941 - val_accuracy: 0.8235 - val_loss: 0.4837\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9863 - loss: 0.0658 - val_accuracy: 0.8235 - val_loss: 0.4757\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0395 - val_accuracy: 0.8235 - val_loss: 0.4822\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9842 - loss: 0.0504 - val_accuracy: 0.8235 - val_loss: 0.5027\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9811 - loss: 0.0655 - val_accuracy: 0.8529 - val_loss: 0.5204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvD3-kRQ08ro",
        "outputId": "6711431c-1c28-4dd8-d5da-3c5acce38b94"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "Test Accuracy: 0.9048\n",
            "Test Loss: 0.2823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjPKh68b0g9N",
        "outputId": "241c5b01-9df2-49d0-8545-6da17a509ee6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Save model\n",
        "model.save('sonar_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('sonar_model.h5')\n",
        "\n",
        "# Load data to fit scaler (same as training)\n",
        "data = pd.read_csv('sonar.csv', header=None)\n",
        "X = data.iloc[:, :-1].values\n",
        "scaler = StandardScaler().fit(X)\n",
        "\n",
        "# Prediction function\n",
        "def predict_sonar(*inputs):\n",
        "    # Convert inputs to numpy array\n",
        "    input_data = np.array(inputs, dtype=float).reshape(1, -1)\n",
        "\n",
        "    # Scale input\n",
        "    input_data = scaler.transform(input_data)\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(input_data, verbose=0)\n",
        "    probability = prediction[0][0]\n",
        "\n",
        "    # Return result\n",
        "    return \"Rock\" if probability > 0.5 else \"Mine\", f\"Probability: {probability:.4f}\"\n",
        "\n",
        "# Create input components for 60 features\n",
        "inputs = [gr.Number(label=f\"Feature {i+1}\") for i in range(60)]\n",
        "\n",
        "# Create Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=predict_sonar,\n",
        "    inputs=inputs,\n",
        "    outputs=[gr.Text(label=\"Prediction\"), gr.Text(label=\"Probability\")],\n",
        "    title=\"Sonar Rock vs Mine Prediction\",\n",
        "    description=\"Enter 60 feature values to predict if the sonar signal is from a Rock or Mine.\"\n",
        ")\n",
        "\n",
        "# Launch interface\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "nTa1r16W2IY6",
        "outputId": "dce113a8-c752-403c-8560-ae93e35c16c7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8e0caa2684a736a2e5.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8e0caa2684a736a2e5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}